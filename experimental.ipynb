{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "233e42c8",
      "metadata": {
        "id": "233e42c8",
        "outputId": "eb2323f9-aebf-4426-e90c-c7ed0f429c54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/tf_clone/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "Using cache found in /Users/nemo/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /Users/nemo/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /Users/nemo/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "# Importing the librariies and function initialization #\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import colors\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from scipy import spatial\n",
        "import random\n",
        "import sklearn.metrics as metrics\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import hashlib\n",
        "pca = PCA(n_components=15) # PCA using first 15 principal components\n",
        "import hashlib\n",
        "resnet_vgg = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "resnet_casia = InceptionResnetV1(pretrained='casia-webface').eval()\n",
        "resnet_v3 = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True).eval()\n",
        "alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True).eval()\n",
        "resnext = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True).eval()\n",
        "mtcnn = MTCNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "007a1a52",
      "metadata": {
        "id": "007a1a52"
      },
      "outputs": [],
      "source": [
        "# Create an embedding using inception resnet and creation of features and targets #\n",
        "\n",
        "def embedding_creation(newimg,prtrn):\n",
        "\n",
        "    width = 416\n",
        "    height = 416\n",
        "    dim = (width, height)\n",
        "\n",
        "    img = cv2.imread(newimg)\n",
        "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    img_cropped = mtcnn(resized)\n",
        "\n",
        "    if(prtrn == 1):\n",
        "        img_embedding = resnet_vgg(img_cropped.unsqueeze(0))\n",
        "    if(prtrn == 2):\n",
        "        img_embedding = resnet_casia(img_cropped.unsqueeze(0))\n",
        "    if(prtrn == 3):\n",
        "        img_embedding = resnet_v3(img_cropped.unsqueeze(0))\n",
        "    if(prtrn == 4):\n",
        "        img_embedding = alexnet(img_cropped.unsqueeze(0))\n",
        "    if(prtrn == 5):\n",
        "        img_embedding = resnext(img_cropped.unsqueeze(0))\n",
        "\n",
        "\n",
        "    img_array = img_embedding.detach().numpy()\n",
        "\n",
        "    return(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb955c6",
      "metadata": {
        "id": "edb955c6"
      },
      "outputs": [],
      "source": [
        "def vector_creation(foldername,prtrn):\n",
        "\n",
        "    datafolder = (os.getcwd() + '/' + str(foldername) + '/')\n",
        "    mydirs = (os.listdir(datafolder))\n",
        "    all_data = []\n",
        "    Y_all = []\n",
        "\n",
        "    if 'random' in foldername:\n",
        "        all_random = []\n",
        "        Y_random = []\n",
        "\n",
        "        for file in mydirs:\n",
        "            mypath = os.path.join(datafolder + file)\n",
        "\n",
        "            try:\n",
        "                all_random.append(embedding_creation(mypath,prtrn))\n",
        "                Y_random.append(0)\n",
        "            except:\n",
        "                print(file)\n",
        "    #return(np.shape(all_random))\n",
        "\n",
        "        all_random = np.array(all_random)\n",
        "        X_random = all_random.reshape(all_random.shape[0], (all_random.shape[1]*all_random.shape[2]))\n",
        "        X_random = np.around(X_random,4)\n",
        "\n",
        "        Y_random = np.array(Y_random)\n",
        "\n",
        "        return (X_random,Y_random)\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "        i = 1\n",
        "\n",
        "        for mydir in mydirs:\n",
        "\n",
        "            for file in os.listdir(datafolder + '/' + mydir):\n",
        "                mypath = os.path.join(datafolder + '/' + mydir + '/'+ file)\n",
        "                all_data.append(embedding_creation(mypath,prtrn))\n",
        "\n",
        "                Y_all.append(i)\n",
        "\n",
        "            i+=1\n",
        "\n",
        "        all_data = np.array(all_data)\n",
        "        X_data = all_data.reshape(all_data.shape[0], (all_data.shape[1]*all_data.shape[2]))\n",
        "        X_data = np.around(X_data,4)\n",
        "\n",
        "        Y_data = np.array(Y_all)\n",
        "\n",
        "        return (X_data,Y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d5c5e7e",
      "metadata": {
        "id": "5d5c5e7e"
      },
      "outputs": [],
      "source": [
        "A_data = vector_creation('att_master',1)[0]\n",
        "B_data = vector_creation('att_master',2)[0]\n",
        "C_data = vector_creation('att_master',3)[0]\n",
        "D_data = vector_creation('att_master',4)[0]\n",
        "E_data = vector_creation('att_master',5)[0]\n",
        "Y_data = vector_creation('att_master',1)[1]\n",
        "\n",
        "A_random = vector_creation('2k_random_images',1)[0]\n",
        "B_random = vector_creation('2k_random_images',2)[0]\n",
        "C_random = vector_creation('2k_random_images',3)[0]\n",
        "D_random = vector_creation('2k_random_images',4)[0]\n",
        "E_random = vector_creation('2k_random_images',5)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a958767",
      "metadata": {
        "id": "2a958767"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity_comparison(i,j,dataset,vector):\n",
        "\n",
        "        # This is for comparison with template class #\n",
        "    thresh = 0\n",
        "    if(vector == 'A'):\n",
        "        sample1 = A_data[i]\n",
        "        if(dataset ==0):\n",
        "            sample2 = A_random[j]\n",
        "\n",
        "        else:\n",
        "            sample2 = A_data[j]\n",
        "    if(vector == 'B'):\n",
        "        sample1 = B_data[i]\n",
        "        if(dataset ==0):\n",
        "            sample2 = B_random[j]\n",
        "        else:\n",
        "            sample2 = B_data[j]\n",
        "\n",
        "    if(vector == 'C'):\n",
        "        sample1 = C_data[i]\n",
        "        if(dataset ==0):\n",
        "            sample2 = C_random[j]\n",
        "        else:\n",
        "            sample2 = C_data[j]\n",
        "\n",
        "\n",
        "    if(vector == 'D'):\n",
        "        sample1 = D_data[i]\n",
        "        if(dataset ==0):\n",
        "            sample2 = D_random[j]\n",
        "\n",
        "        else:\n",
        "            sample2 = D_data[j]\n",
        "\n",
        "    if(vector == 'E'):\n",
        "        sample1 = E_data[i]\n",
        "        if(dataset ==0):\n",
        "            sample2 = E_random[j]\n",
        "\n",
        "        else:\n",
        "            sample2 = E_data[j]\n",
        "\n",
        "    result = 1 - spatial.distance.cosine(sample1, sample2)\n",
        "    return round(result,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f8908a",
      "metadata": {
        "id": "25f8908a"
      },
      "outputs": [],
      "source": [
        "### Distribution generation function for class 1 , class 2 and random images ###\n",
        "\n",
        "template_class_dist_vector_A = []\n",
        "random_class_dist_vector_A = []\n",
        "\n",
        "template_class_dist_vector_B = []\n",
        "random_class_dist_vector_B = []\n",
        "\n",
        "template_class_dist_vector_C = []\n",
        "random_class_dist_vector_C = []\n",
        "\n",
        "template_class_dist_vector_D = []\n",
        "random_class_dist_vector_D = []\n",
        "\n",
        "template_class_dist_vector_E = []\n",
        "random_class_dist_vector_E = []\n",
        "\n",
        "# (i,j,dataset,vector) #\n",
        "j = 0\n",
        "\n",
        "for j in range(0,400,10):\n",
        "    i = 0\n",
        "    for i in range(j,j+10):\n",
        "\n",
        "        template_class_dist_vector_A.append(cosine_similarity_comparison(j,i,1,'A'))\n",
        "        random_class_dist_vector_A.append(cosine_similarity_comparison(j,i,0,'A'))\n",
        "\n",
        "        template_class_dist_vector_B.append(cosine_similarity_comparison(j,i,1,'B'))\n",
        "        random_class_dist_vector_B.append(cosine_similarity_comparison(j,i,0,'B'))\n",
        "\n",
        "        template_class_dist_vector_C.append(cosine_similarity_comparison(j,i,1,'C'))\n",
        "        random_class_dist_vector_C.append(cosine_similarity_comparison(j,i,0,'C'))\n",
        "\n",
        "        template_class_dist_vector_D.append(cosine_similarity_comparison(j,i,1,'D'))\n",
        "        random_class_dist_vector_D.append(cosine_similarity_comparison(j,i,0,'D'))\n",
        "\n",
        "\n",
        "        template_class_dist_vector_E.append(cosine_similarity_comparison(j,i,1,'E'))\n",
        "        random_class_dist_vector_E.append(cosine_similarity_comparison(j,i,0,'E'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d00ba2f",
      "metadata": {
        "id": "3d00ba2f"
      },
      "outputs": [],
      "source": [
        "len(random_class_dist_vector_A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83214e1c",
      "metadata": {
        "id": "83214e1c"
      },
      "outputs": [],
      "source": [
        "### Histogram plotting ###\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "axs[0].hist(template_class_dist_vector_A, bins=10)\n",
        "axs[1].hist(random_class_dist_vector_A, bins=10)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "axs[0].hist(template_class_dist_vector_B, bins=10)\n",
        "axs[1].hist(random_class_dist_vector_B, bins=10)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "axs[0].hist(template_class_dist_vector_C, bins=10)\n",
        "axs[1].hist(random_class_dist_vector_C, bins=10)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "axs[0].hist(template_class_dist_vector_D, bins=10)\n",
        "axs[1].hist(random_class_dist_vector_D, bins=10)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "axs[0].hist(template_class_dist_vector_E, bins=10)\n",
        "axs[1].hist(random_class_dist_vector_E, bins=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ebd0c7",
      "metadata": {
        "id": "55ebd0c7"
      },
      "outputs": [],
      "source": [
        "## plotting ROC for various condition ##\n",
        "\n",
        "def roc_creation(distro1,distro2):\n",
        "\n",
        "    genuine_label = list(np.ones(400, dtype = int))\n",
        "    imposter_label = list(np.zeros(400, dtype = int))\n",
        "    y_test = np.concatenate([np.array(genuine_label), np.array(imposter_label)])\n",
        "\n",
        "    # return y_test\n",
        "\n",
        "    genuine_label = list(distro1)\n",
        "    imposter_label = list(distro2)\n",
        "    y_prob = np.concatenate([np.array(genuine_label), np.array(imposter_label)])\n",
        "\n",
        "\n",
        "\n",
        "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_prob)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "\n",
        "\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d449a2a",
      "metadata": {
        "id": "9d449a2a"
      },
      "outputs": [],
      "source": [
        "roc_creation(template_class_dist_vector_E,random_class_dist_vector_A)\n",
        "roc_creation(template_class_dist_vector_E,random_class_dist_vector_B)\n",
        "roc_creation(template_class_dist_vector_E,random_class_dist_vector_C)\n",
        "roc_creation(template_class_dist_vector_E,random_class_dist_vector_D)\n",
        "roc_creation(template_class_dist_vector_E,random_class_dist_vector_E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a0bbdf",
      "metadata": {
        "id": "d5a0bbdf"
      },
      "outputs": [],
      "source": [
        "# new hash generation function #\n",
        "def newhash(mystring):\n",
        "\n",
        "    encoded=mystring.encode()\n",
        "    result = hashlib.sha256(encoded)\n",
        "\n",
        "    #print(\"Block Size : \", end =\"\")\n",
        "    #print(result.block_size)\n",
        "\n",
        "    return(result.hexdigest())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e5bdd5d",
      "metadata": {
        "id": "4e5bdd5d"
      },
      "outputs": [],
      "source": [
        "# generic hash function testing #\n",
        "\n",
        "fixed_hash = 'a36b1f2c3f84522dd1005145646617d7054c0851e97c72a039c0bdfac9fa07f3'\n",
        "\n",
        "current_hash = newhash(str([1,2,3]))\n",
        "\n",
        "\n",
        "if(current_hash == fixed_hash):\n",
        "    print('Hash function is working properly')\n",
        "else:\n",
        "    print(\"There is some issue with hash function\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bd85499",
      "metadata": {
        "id": "9bd85499"
      },
      "outputs": [],
      "source": [
        "# template image hash generation #\n",
        "\n",
        "i = 0\n",
        "A0 = []\n",
        "B0 = []\n",
        "C0 = []\n",
        "D0 = []\n",
        "E0 = []\n",
        "\n",
        "for i in range(0,400,10):\n",
        "    A0.append(A_data[i])\n",
        "    B0.append(B_data[i])\n",
        "    C0.append(C_data[i])\n",
        "    D0.append(D_data[i])\n",
        "    E0.append(E_data[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdda510f",
      "metadata": {
        "id": "fdda510f"
      },
      "outputs": [],
      "source": [
        "m0 = newhash(str([A0[0],B0[1],C0[0],D0[0],E0[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "242198fe",
      "metadata": {
        "id": "242198fe"
      },
      "outputs": [],
      "source": [
        "# advanced hash function testing #\n",
        "\n",
        "if (m0 == 'bbd58fca367aec3ac6f0d9d8d52297cdc8a1ae532037ac1480c2b16120394ac2'):\n",
        "    print(\"hash generation of vector points is working fine\")\n",
        "else:\n",
        "    print(\"please check hash generation of vector points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e209e74",
      "metadata": {
        "id": "0e209e74"
      },
      "outputs": [],
      "source": [
        "### key generation ###\n",
        "\n",
        "key_master = []\n",
        "\n",
        "for i in range(400):\n",
        "    key_master.append(newhash(str([A_data[i],B_data[i],C_data[i],D_data[i],E_data[i]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642f5aec",
      "metadata": {
        "id": "642f5aec"
      },
      "outputs": [],
      "source": [
        "### vault preparation ###\n",
        "\n",
        "vault_A_cosines = []\n",
        "vault_B_cosines = []\n",
        "vault_C_cosines = []\n",
        "vault_D_cosines = []\n",
        "vault_E_cosines = []\n",
        "\n",
        "\n",
        "vault_A_2k1 = []\n",
        "vault_B_2k1 = []\n",
        "vault_C_2k1 = []\n",
        "vault_D_2k1 = []\n",
        "vault_E_2k1 = []\n",
        "\n",
        "\n",
        "\n",
        "matched = 0\n",
        "unmatched = 0\n",
        "\n",
        "j=0\n",
        "\n",
        "for j in range(400):\n",
        "\n",
        "    vault_A_cosines = []\n",
        "    vault_B_cosines = []\n",
        "    vault_C_cosines = []\n",
        "    vault_D_cosines = []\n",
        "    vault_E_cosines = []\n",
        "\n",
        "    vault_A_2k1 = []\n",
        "    vault_B_2k1 = []\n",
        "    vault_C_2k1 = []\n",
        "    vault_D_2k1 = []\n",
        "    vault_E_2k1 = []\n",
        "\n",
        "\n",
        "    vault_A_cosines.append(1 - spatial.distance.cosine(A_data[j], A_data[j]))\n",
        "    vault_B_cosines.append(1 - spatial.distance.cosine(B_data[j], B_data[j]))\n",
        "    vault_C_cosines.append(1 - spatial.distance.cosine(C_data[j], C_data[j]))\n",
        "    vault_D_cosines.append(1 - spatial.distance.cosine(D_data[j], D_data[j]))\n",
        "    vault_E_cosines.append(1 - spatial.distance.cosine(E_data[j], E_data[j]))\n",
        "\n",
        "    vault_A_2k1.append(A_data[j])\n",
        "    vault_B_2k1.append(B_data[j])\n",
        "    vault_C_2k1.append(C_data[j])\n",
        "    vault_D_2k1.append(D_data[j])\n",
        "    vault_E_2k1.append(E_data[j])\n",
        "\n",
        "    i = 0\n",
        "    for i in range(2000):\n",
        "\n",
        "        vault_A_cosines.append(1 - spatial.distance.cosine(A_data[j], A_random[i]))\n",
        "        vault_B_cosines.append(1 - spatial.distance.cosine(B_data[j], B_random[i]))\n",
        "        vault_B_cosines.append(1 - spatial.distance.cosine(C_data[j], C_random[i]))\n",
        "        vault_D_cosines.append(1 - spatial.distance.cosine(D_data[j], D_random[i]))\n",
        "        vault_E_cosines.append(1 - spatial.distance.cosine(E_data[j], E_random[i]))\n",
        "\n",
        "\n",
        "        vault_A_2k1.append(A_random[i])\n",
        "        vault_B_2k1.append(B_random[i])\n",
        "        vault_C_2k1.append(C_random[i])\n",
        "        vault_D_2k1.append(D_random[i])\n",
        "        vault_E_2k1.append(E_random[i])\n",
        "\n",
        "    index_a = vault_A_cosines.index(max(vault_A_cosines))\n",
        "    index_b = vault_B_cosines.index(max(vault_B_cosines))\n",
        "    index_c = vault_C_cosines.index(max(vault_C_cosines))\n",
        "    index_d = vault_D_cosines.index(max(vault_D_cosines))\n",
        "    index_e = vault_E_cosines.index(max(vault_E_cosines))\n",
        "\n",
        "    m_compare = newhash(str([vault_A_2k1[index_a],vault_B_2k1[index_b],vault_C_2k1[index_c],vault_D_2k1[index_d],vault_E_2k1[index_e]]))\n",
        "\n",
        "    if(key_master[j] == m_compare):\n",
        "        matched += 1\n",
        "    else:\n",
        "        unmatched += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23dc47b7",
      "metadata": {
        "id": "23dc47b7"
      },
      "outputs": [],
      "source": [
        "matched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba64e3c0",
      "metadata": {
        "id": "ba64e3c0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf_clone] *",
      "language": "python",
      "name": "conda-env-tf_clone-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}